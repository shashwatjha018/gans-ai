{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "import os\n", "from PIL import Image\n", "from torchvision.transforms import ToTensor, Resize\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def shuffle_data(inputs, outputs):\n", "    \"\"\"Shuffle the first dimension of a set of input/output data\"\"\"\n", "    n_examples = outputs.shape[0]\n", "    shuffled_indices = torch.randperm(n_examples)\n", "    inputs = inputs[shuffled_indices]\n", "    outputs = outputs[shuffled_indices]\n", "    return inputs, outputs"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def batch_data(inputs, outputs, batch_size=16):\n", "    \"\"\"Convert full input/output pairs to a list of batched tuples\"\"\"\n", "    n_examples = outputs.shape[0]\n", "    return [\n", "        (\n", "            inputs[batch_size * i : batch_size * (i + 1)],\n", "            outputs[batch_size * i : batch_size * (i + 1)],\n", "        )\n", "        for i in range(n_examples // batch_size)\n", "    ]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def train_batch(model, batch):\n", "    \"\"\"Perform one iteration of model training given a single batch\"\"\"\n", "    # send data to CUDA if necessary\n", "    inputs, correct_outputs = batch\n", "    if model.device:\n", "        inputs = inputs.to(model.device)\n", "        correct_outputs = correct_outputs.to(model.device)\n\n", "    # train batch\n", "    model_outputs = model.forward(inputs)\n", "    model.optimizer.zero_grad()\n", "    loss = model.criterion(model_outputs, correct_outputs)\n", "    loss.backward(retain_graph=True)\n", "    model.optimizer.step()\n\n", "    # return data to CPU if necessary\n", "    if model.device:\n", "        inputs = inputs.to(torch.device(\"cpu\"))\n", "        correct_outputs = correct_outputs.to(torch.device(\"cpu\"))\n", "    return float(loss) / model_outputs.shape[0]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def fit(model, inputs, correct_outputs, num_epochs=10):\n", "    \"\"\"Train model on input/output pairs over desired number of epochs\"\"\"\n", "    epoch_loss = 0\n", "    for epoch in range(1, num_epochs + 1):\n", "        # sort data into minibatches\n", "        inputs, correct_outputs = shuffle_data(inputs, correct_outputs)\n", "        minibatches = batch_data(inputs, correct_outputs)\n\n", "        # train on each minibatch\n", "        epoch_loss = 0\n", "        for batch in minibatches:\n", "            epoch_loss += train_batch(model, batch)\n", "        epoch_loss /= len(minibatches)\n\n", "        # output loss\n", "        if epoch % 10 == 0:\n", "            print(\"Epoch {} loss: {}\".format(epoch, epoch_loss))\n\n", "    # return training accuracy\n", "    return epoch_loss"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def load_faces(num_faces, dir_1, suffix_1, dir_2, suffix_2):\n", "    # confirm that directories exist\n", "    assert os.path.isdir(dir_1)\n", "    assert os.path.isdir(dir_2)\n\n", "    # load data\n", "    img_size = 128\n", "    faces_1 = torch.zeros((num_faces, 3, img_size, img_size))\n", "    faces_2 = torch.zeros((num_faces, 3, img_size, img_size))\n", "    plt.figure()\n", "    fig, axes = plt.subplots(2, 5)\n", "    fig.set_figwidth(20)\n", "    fig.set_figheight(7)\n", "    face_id = 0\n", "    skipped = 0\n", "    idx_to_face_id = []\n", "    while face_id < num_faces and skipped < num_faces:\n", "        # get image paths\n", "        face_id_text = str(100000 + face_id + skipped)[1:]\n", "        path_1 = \"{}/{}{}\".format(dir_1, face_id_text, suffix_1)\n", "        path_2 = \"{}/{}{}\".format(dir_2, face_id_text, suffix_2)\n\n", "        # load images\n", "        try:\n", "            img_1 = Image.open(path_1)\n", "            img_2 = Image.open(path_2)\n", "        except:  # skip missing images\n", "            skipped += 1\n", "            continue\n\n", "        # process images\n", "        tensor_1 = Resize((img_size, img_size))(ToTensor()(img_1)) - 0.5\n", "        tensor_2 = Resize((img_size, img_size))(ToTensor()(img_2)) - 0.5\n", "        if tensor_1 is None or tensor_2 is None:\n", "            skipped += 1\n", "            continue\n\n", "        # display images\n", "        if face_id < 5:\n", "            axes[0, face_id].imshow(img_1)\n", "            axes[0, face_id].set_axis_off()\n", "            axes[1, face_id].imshow(img_2)\n", "            axes[1, face_id].set_axis_off()\n\n", "        # save images to respective tensors\n", "        faces_1[face_id] = tensor_1\n", "        faces_2[face_id] = tensor_2\n", "        idx_to_face_id.append(face_id_text)\n", "        face_id += 1\n\n", "    # warn that `num_faces` was too large\n", "    if skipped > num_faces:\n", "        print(\n", "            \"NOTE: `num_faces` is larger than total capacity of chosen directories ({}, {})\".format(\n", "                dir_1, dir_2\n", "            )\n", "        )\n\n", "    # return\n", "    return faces_1, faces_2, idx_to_face_id"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}